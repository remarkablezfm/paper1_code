{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8181c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 14:02:12.202471: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-06 14:02:12.203816: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-06 14:02:12.233262: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-06 14:02:12.234503: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-06 14:02:12.982318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ç¯å¢ƒåŠ è½½æˆåŠŸï¼\n",
      "   - TensorFlow: 2.13.0\n",
      "   - Camera Ops: å·²åŠ è½½\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# 1. è§£å†³ç»˜å›¾åç«¯é—®é¢˜ (ä¿ç•™ä½ ä¹‹å‰çš„ TkAgg ä¿®å¤)\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "matplotlib.use('TkAgg', force=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2. å¯¼å…¥ Waymo æ•°æ®å®šä¹‰\n",
    "try:\n",
    "    from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "    # å°è¯•å¯¼å…¥ E2E æ•°æ®å®šä¹‰\n",
    "    from waymo_open_dataset.protos import end_to_end_driving_data_pb2 as wod_e2ed_pb2\n",
    "    # âš ï¸ å…³é”®ï¼šå¯¼å…¥å®˜æ–¹ Demo ä½¿ç”¨çš„ç›¸æœºæŠ•å½±ç®—å­\n",
    "    from waymo_open_dataset.wdl_limited.camera.ops import py_camera_model_ops\n",
    "    print(f\"âœ… ç¯å¢ƒåŠ è½½æˆåŠŸï¼\")\n",
    "    print(f\"   - TensorFlow: {tf.__version__}\")\n",
    "    print(f\"   - Camera Ops: å·²åŠ è½½\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"æç¤º: è¯·ç¡®ä¿å®‰è£…äº† waymo-open-dataset-tf-2-12-0 (æˆ–å…¼å®¹ç‰ˆæœ¬)\")\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01299d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ç›®æ ‡æ–‡ä»¶: /mnt/d/Datasets/WOD_E2E_Camera_v1/val/val_202504211843.tfrecord-00008-of-00093\n",
      "âœ… TFRecordDataset å·²å°±ç»ªï¼Œcompression_type=''\n",
      "ğŸ“¦ å‰ 3 æ¡ record bytes é•¿åº¦: [2275686, 1571030, 2162981]\n",
      "âœ… è§£ææˆåŠŸ: wod_e2ed_pb2.E2EDFrame\n",
      "ğŸ” é¡¶å±‚å­—æ®µé¢„è§ˆ: ['frame', 'future_states', 'past_states', 'intent', 'preference_trajectories']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 14:02:18.745337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-01-06 14:02:18.745599: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from google.protobuf.message import DecodeError\n",
    "\n",
    "# ä¿®æ”¹ä¸ºä½ çš„å®é™…æ–‡ä»¶è·¯å¾„\n",
    "FILENAME = r'D:\\Datasets\\WOD_E2E_Camera_v1\\val\\val_202504211843.tfrecord-00008-of-00093'\n",
    "\n",
    "# ---- 1) è·¯å¾„å…¼å®¹ï¼šWindows -> WSLï¼ˆå¯é€‰ï¼‰\n",
    "if (not os.path.exists(FILENAME)) and ('mnt' not in FILENAME) and (':' in FILENAME):\n",
    "    FILENAME = FILENAME.replace('D:', '/mnt/d').replace('\\\\', '/')\n",
    "\n",
    "print(f\"ğŸ“‚ ç›®æ ‡æ–‡ä»¶: {FILENAME}\")\n",
    "\n",
    "# ---- 2) æ›´ç¨³çš„ exists åˆ¤æ–­\n",
    "if not tf.io.gfile.exists(FILENAME):\n",
    "    raise FileNotFoundError(f\"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {FILENAME}\")\n",
    "\n",
    "# ---- 3) è‡ªåŠ¨å°è¯•å‹ç¼©ç±»å‹ï¼ˆå…ˆæŒ‰æ‰©å±•åçŒœï¼›ä¸è¡Œå† fallbackï¼‰\n",
    "def make_tfrecord_dataset(path: str):\n",
    "    # å…ˆæŒ‰åç¼€çŒœ\n",
    "    guess = \"GZIP\" if path.endswith(\".gz\") else \"\"\n",
    "    tried = []\n",
    "    for comp in [guess, \"GZIP\", \"\"]:\n",
    "        if comp in tried:\n",
    "            continue\n",
    "        tried.append(comp)\n",
    "        try:\n",
    "            ds = tf.data.TFRecordDataset(path, compression_type=comp)\n",
    "            # è§¦å‘è¯»å–ä¸€æ¡ï¼ŒéªŒè¯å‹ç¼©ç±»å‹å¯¹ä¸å¯¹\n",
    "            _ = next(iter(ds.take(1))).numpy()\n",
    "            return ds, comp\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"âŒ TFRecord è¯»å–å¤±è´¥ï¼ˆå·²å°è¯•å‹ç¼© {tried}ï¼‰ï¼Œæœ€åé”™è¯¯ï¼š{repr(last_err)}\")\n",
    "\n",
    "dataset, used_comp = make_tfrecord_dataset(FILENAME)\n",
    "print(f\"âœ… TFRecordDataset å·²å°±ç»ªï¼Œcompression_type='{used_comp}'\")\n",
    "\n",
    "# ---- 4) è¯»å‡ æ¡ raw bytes åš sanity check\n",
    "raw_list = [x.numpy() for x in dataset.take(3)]\n",
    "print(\"ğŸ“¦ å‰ 3 æ¡ record bytes é•¿åº¦:\", [len(b) for b in raw_list])\n",
    "\n",
    "# ---- 5) å°è¯•è§£æä¸º WOD-E2E protoï¼ˆä½ å·²å¯¼å…¥ wod_e2ed_pb2ï¼‰\n",
    "#     è¿™é‡Œä¸å‡è®¾å…·ä½“ message åå­—ï¼Œè‡ªåŠ¨æšä¸¾ pb2 é‡Œçš„ message class é€ä¸ªå°è¯• ParseFromString\n",
    "def parse_as_any_e2e_message(raw_bytes, pb2_module):\n",
    "    candidates = []\n",
    "    for name, obj in vars(pb2_module).items():\n",
    "        if isinstance(obj, type) and hasattr(obj, \"DESCRIPTOR\"):\n",
    "            candidates.append((name, obj))\n",
    "\n",
    "    # ä¼˜å…ˆå°è¯•åå­—åƒ segment/frame/data çš„\n",
    "    priority = [\"EndToEnd\", \"E2E\", \"Driving\", \"Segment\", \"Frame\", \"Data\"]\n",
    "    candidates.sort(key=lambda x: sum(p in x[0] for p in priority), reverse=True)\n",
    "\n",
    "    for name, cls in candidates:\n",
    "        msg = cls()\n",
    "        try:\n",
    "            msg.ParseFromString(raw_bytes)\n",
    "            if len(msg.ListFields()) > 0:\n",
    "                return name, msg\n",
    "        except DecodeError:\n",
    "            pass\n",
    "    return None, None\n",
    "\n",
    "# ä½ ä¸Šé¢å·²ç»å¯¼å…¥äº†ï¼šfrom waymo_open_dataset.protos import end_to_end_driving_data_pb2 as wod_e2ed_pb2\n",
    "msg_name, msg = parse_as_any_e2e_message(raw_list[0], wod_e2ed_pb2)\n",
    "\n",
    "if msg is None:\n",
    "    print(\"âš ï¸ è¯»åˆ°äº† bytesï¼Œä½†æ²¡æ³•è§£ææˆ end_to_end_driving_data_pb2 é‡Œçš„ä»»ä½• messageã€‚\")\n",
    "    print(\"   - å¯èƒ½åŸå› ï¼šå‹ç¼©ç±»å‹ä»ä¸å¯¹ï¼›æˆ–è¯¥ tfrecord ä¸æ˜¯ E2E protoï¼›æˆ–ç‰ˆæœ¬ä¸åŒ¹é…ã€‚\")\n",
    "else:\n",
    "    print(f\"âœ… è§£ææˆåŠŸ: wod_e2ed_pb2.{msg_name}\")\n",
    "    print(\"ğŸ” é¡¶å±‚å­—æ®µé¢„è§ˆ:\", [fd.name for fd, _ in msg.ListFields()][:40])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759d821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bc7c885",
   "metadata": {},
   "source": [
    "### Block 1ï¼šåŸºç¡€å¯¼å…¥ + è§£æä¸€æ¡ E2EDFrameï¼ˆæœ€å°èµ·æ­¥ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5e743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Parsed E2EDFrame.\n",
      "Top-level set fields: ['frame', 'future_states', 'past_states', 'intent', 'preference_trajectories']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from google.protobuf.descriptor import FieldDescriptor\n",
    "\n",
    "def parse_e2ed_frame_from_dataset(dataset):\n",
    "    \"\"\"ä» TFRecordDataset å–ç¬¬ä¸€æ¡ record å¹¶è§£æä¸º E2EDFrame\"\"\"\n",
    "    raw = next(iter(dataset.take(1))).numpy()\n",
    "    msg = wod_e2ed_pb2.E2EDFrame()\n",
    "    msg.ParseFromString(raw)\n",
    "    return msg\n",
    "\n",
    "e2e = parse_e2ed_frame_from_dataset(dataset)\n",
    "print(\"âœ… Parsed E2EDFrame.\")\n",
    "print(\"Top-level set fields:\", [fd.name for fd,_ in e2e.ListFields()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc08a1",
   "metadata": {},
   "source": [
    "### Block 2ï¼šé€šç”¨ Proto æ£€æŸ¥å‡½æ•°ï¼ˆåé¢æ‰€æœ‰æ¨¡å—éƒ½å¤ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f86996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pb_set_fields(msg, title=\"\", max_fields=80):\n",
    "    \"\"\"åªæ‰“å°å½“å‰ message é‡Œè¢« set çš„å­—æ®µï¼ˆListFieldsï¼‰\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n=== {title} (set fields) ===\")\n",
    "    for fd, val in msg.ListFields()[:max_fields]:\n",
    "        if fd.label == FieldDescriptor.LABEL_REPEATED:\n",
    "            print(f\"- {fd.name}: repeated len={len(val)}\")\n",
    "        else:\n",
    "            if hasattr(val, \"ListFields\"):\n",
    "                print(f\"- {fd.name}: message<{fd.message_type.name}> subfields={len(val.ListFields())}\")\n",
    "            else:\n",
    "                print(f\"- {fd.name}: {val}\")\n",
    "\n",
    "def pb_all_fields(msg, title=\"\"):\n",
    "    \"\"\"æ‰“å° proto å®šä¹‰ä¸­çš„å…¨éƒ¨å­—æ®µï¼ˆä¸ç®¡ set æ²¡ setï¼‰\"\"\"\n",
    "    if title:\n",
    "        print(f\"\\n=== {title} (all defined fields) ===\")\n",
    "    for f in msg.DESCRIPTOR.fields:\n",
    "        rep = \"repeated\" if f.label == f.LABEL_REPEATED else \"scalar\"\n",
    "        print(f\"- {f.name}: {rep}, type={f.type}\")\n",
    "\n",
    "def pb_find_defined_fields(msg, keywords):\n",
    "    \"\"\"åœ¨â€œå­—æ®µå®šä¹‰â€é‡ŒæŒ‰å…³é”®è¯æ‰¾å­—æ®µåï¼ˆä¸æ˜¯ ListFieldsï¼‰\"\"\"\n",
    "    ks = [k.lower() for k in keywords]\n",
    "    hits = []\n",
    "    for f in msg.DESCRIPTOR.fields:\n",
    "        name = f.name.lower()\n",
    "        if any(k in name for k in ks):\n",
    "            hits.append(f.name)\n",
    "    return hits\n",
    "\n",
    "def enum_name(enum_wrapper, value):\n",
    "    \"\"\"ç¨³å®šçš„ enum number -> nameï¼ˆé¿å… .Name() ç‰ˆæœ¬å·®å¼‚ï¼‰\"\"\"\n",
    "    try:\n",
    "        value_int = int(value)\n",
    "    except Exception:\n",
    "        value_int = value\n",
    "    try:\n",
    "        return enum_wrapper.DESCRIPTOR.values_by_number[value_int].name\n",
    "    except Exception:\n",
    "        return str(value)\n",
    "\n",
    "def cam_name_from_id(cam_id):\n",
    "    \"\"\"CameraName enum -> string\"\"\"\n",
    "    return enum_name(open_dataset.CameraName, cam_id) if hasattr(open_dataset, \"CameraName\") else str(cam_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fabaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9095e67b",
   "metadata": {},
   "source": [
    "### Block 3ï¼šframe æ¨¡å—æ€»è§ˆï¼ˆframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0bec51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FRAME OVERVIEW ==========\n",
      "\n",
      "=== frame (set fields) ===\n",
      "- context: message<Context> subfields=2\n",
      "- timestamp_micros: 0\n",
      "- images: repeated len=8\n",
      "\n",
      "[Defined-field search]\n",
      "('images',) -> ['images']\n",
      "('context', 'calibr') -> ['context']\n",
      "('pose',) -> ['pose', 'map_pose_offset']\n",
      "('lidar',) -> ['projected_lidar_labels']\n",
      "('labels',) -> ['laser_labels', 'projected_lidar_labels', 'camera_labels']\n",
      "('map',) -> ['map_features', 'map_pose_offset']\n",
      "\n",
      "num images: 8\n",
      "num camera_calibrations: 8\n"
     ]
    }
   ],
   "source": [
    "def inspect_frame_overview(frame):\n",
    "    print(\"\\n========== FRAME OVERVIEW ==========\")\n",
    "    pb_set_fields(frame, \"frame\", max_fields=60)\n",
    "\n",
    "    # keyword search in defined fields\n",
    "    print(\"\\n[Defined-field search]\")\n",
    "    groups = [\n",
    "        (\"images\",),\n",
    "        (\"context\", \"calibr\"),\n",
    "        (\"pose\",),\n",
    "        (\"lidar\",),\n",
    "        (\"labels\",),\n",
    "        (\"map\",),\n",
    "    ]\n",
    "    for kws in groups:\n",
    "        hits = pb_find_defined_fields(frame, kws)\n",
    "        print(f\"{kws} -> {hits}\")\n",
    "\n",
    "    # common quick stats\n",
    "    if hasattr(frame, \"images\"):\n",
    "        print(\"\\nnum images:\", len(frame.images))\n",
    "    if hasattr(frame, \"context\") and hasattr(frame.context, \"camera_calibrations\"):\n",
    "        print(\"num camera_calibrations:\", len(frame.context.camera_calibrations))\n",
    "\n",
    "frame = e2e.frame\n",
    "inspect_frame_overview(frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385fb03",
   "metadata": {},
   "source": [
    "### Block 4ï¼šframe çš„ 8 è·¯ç›¸æœºå›¾åƒæå– + å¯è§†åŒ–ï¼ˆframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aca4b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FRAME IMAGES META ==========\n",
      "- 2 (id=2): bytes=329031, shape=(1079, 972, 3)\n",
      "- 1 (id=1): bytes=206775, shape=(1079, 972, 3)\n",
      "- 3 (id=3): bytes=363232, shape=(1079, 972, 3)\n",
      "- 4 (id=4): bytes=282652, shape=(1079, 972, 3)\n",
      "- 5 (id=5): bytes=426742, shape=(1079, 972, 3)\n",
      "- 8 (id=8): bytes=255339, shape=(587, 972, 3)\n",
      "- 7 (id=7): bytes=202958, shape=(551, 972, 3)\n",
      "- 6 (id=6): bytes=204414, shape=(587, 972, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_frame_images(frame):\n",
    "    \"\"\"\n",
    "    è¿”å›ï¼š\n",
    "      images: list[np.ndarray]  HWC uint8\n",
    "      labels: list[str]         ç›¸æœºå\n",
    "      meta:   list[dict]        cam_id/bytes_len/shape\n",
    "    \"\"\"\n",
    "    images, labels, meta = [], [], []\n",
    "    for img in frame.images:\n",
    "        cam_id = img.name\n",
    "        name = cam_name_from_id(cam_id)\n",
    "        b = img.image\n",
    "        arr = tf.io.decode_jpeg(b).numpy()\n",
    "        images.append(arr)\n",
    "        labels.append(name)\n",
    "        meta.append({\"cam_id\": int(cam_id), \"cam_name\": name, \"bytes_len\": len(b), \"shape\": arr.shape})\n",
    "    return images, labels, meta\n",
    "\n",
    "def print_images_meta(meta):\n",
    "    print(\"\\n========== FRAME IMAGES META ==========\")\n",
    "    for m in meta:\n",
    "        print(f\"- {m['cam_name']} (id={m['cam_id']}): bytes={m['bytes_len']}, shape={m['shape']}\")\n",
    "\n",
    "def show_image_grid(images, labels, cols=4, figsize=(14, 8)):\n",
    "    n = len(images)\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(labels[i], fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "images, labels, meta = get_frame_images(frame)\n",
    "print_images_meta(meta)\n",
    "show_image_grid(images, labels, cols=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719789e",
   "metadata": {},
   "source": [
    "### Block 5ï¼šframe çš„ç›¸æœºæ ‡å®šæå–ï¼ˆintrinsics/extrinsicsï¼‰ï¼ˆframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aabbcfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num camera_calibrations: 8\n",
      "\n",
      "========== CAMERA CALIBRATIONS ==========\n",
      "\n",
      "[2] size=(972x1079), fx_fy_cx_cy=[1112.1429443359375, 1112.0059814453125, 488.12847900390625, 719.156005859375]\n",
      "extrinsic_4x4:\n",
      " [[ 0.706 -0.708  0.001  1.445]\n",
      " [ 0.708  0.706  0.009  0.153]\n",
      " [-0.007 -0.005  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[1] size=(972x1079), fx_fy_cx_cy=[1111.67724609375, 1111.5404052734375, 488.12847900390625, 719.156005859375]\n",
      "extrinsic_4x4:\n",
      " [[ 1.     0.002  0.003  1.519]\n",
      " [-0.002  1.     0.008  0.026]\n",
      " [-0.003 -0.008  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[3] size=(972x1079), fx_fy_cx_cy=[1110.81982421875, 1110.68310546875, 488.12847900390625, 719.156005859375]\n",
      "extrinsic_4x4:\n",
      " [[ 0.707  0.707  0.005  1.482]\n",
      " [-0.707  0.707  0.002 -0.116]\n",
      " [-0.002 -0.005  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[4] size=(972x1079), fx_fy_cx_cy=[1110.3507080078125, 1110.2139892578125, 488.12847900390625, 719.156005859375]\n",
      "extrinsic_4x4:\n",
      " [[ 0.    -1.    -0.005  1.303]\n",
      " [ 1.    -0.     0.007  0.19 ]\n",
      " [-0.007 -0.005  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[5] size=(972x1079), fx_fy_cx_cy=[1111.13525390625, 1110.9984130859375, 488.12847900390625, 719.156005859375]\n",
      "extrinsic_4x4:\n",
      " [[ 0.003  1.     0.001  1.355]\n",
      " [-1.     0.003 -0.003 -0.19 ]\n",
      " [-0.003 -0.001  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[8] size=(972x587), fx_fy_cx_cy=[1109.8792724609375, 1110.35693359375, 488.12847900390625, 310.7125244140625]\n",
      "extrinsic_4x4:\n",
      " [[-0.708  0.706 -0.001  1.213]\n",
      " [-0.706 -0.708 -0.003 -0.153]\n",
      " [-0.003 -0.001  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[7] size=(972x551), fx_fy_cx_cy=[1112.0322265625, 1111.4815673828125, 488.12847900390625, 310.4250183105469]\n",
      "extrinsic_4x4:\n",
      " [[-1.     0.002 -0.008  1.139]\n",
      " [-0.002 -1.    -0.001 -0.026]\n",
      " [-0.008 -0.001  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n",
      "\n",
      "[6] size=(972x587), fx_fy_cx_cy=[1111.7921142578125, 1112.2706298828125, 488.12847900390625, 310.7125244140625]\n",
      "extrinsic_4x4:\n",
      " [[-0.708 -0.706 -0.01   1.176]\n",
      " [ 0.706 -0.708  0.005  0.116]\n",
      " [-0.01  -0.003  1.     1.806]\n",
      " [ 0.     0.     0.     1.   ]]\n"
     ]
    }
   ],
   "source": [
    "def get_camera_calibration_map(frame):\n",
    "    \"\"\"è¿”å› dict: cam_id -> CameraCalibration\"\"\"\n",
    "    calib_map = {}\n",
    "    if hasattr(frame, \"context\") and hasattr(frame.context, \"camera_calibrations\"):\n",
    "        for c in frame.context.camera_calibrations:\n",
    "            calib_map[c.name] = c\n",
    "    return calib_map\n",
    "\n",
    "def calib_summary(calib):\n",
    "    out = {}\n",
    "    if hasattr(calib, \"width\"): out[\"width\"] = calib.width\n",
    "    if hasattr(calib, \"height\"): out[\"height\"] = calib.height\n",
    "    if hasattr(calib, \"intrinsic\"):\n",
    "        intr = list(calib.intrinsic)\n",
    "        out[\"fx_fy_cx_cy\"] = intr[:4] if len(intr) >= 4 else intr\n",
    "    if hasattr(calib, \"extrinsic\") and hasattr(calib.extrinsic, \"transform\"):\n",
    "        ex = list(calib.extrinsic.transform)\n",
    "        if len(ex) == 16:\n",
    "            out[\"extrinsic_4x4\"] = np.array(ex, dtype=np.float32).reshape(4,4)\n",
    "        else:\n",
    "            out[\"extrinsic_flat\"] = ex\n",
    "    return out\n",
    "\n",
    "def print_camera_calibrations(calib_map, max_print=8):\n",
    "    print(\"\\n========== CAMERA CALIBRATIONS ==========\")\n",
    "    for cam_id, calib in list(calib_map.items())[:max_print]:\n",
    "        name = cam_name_from_id(cam_id)\n",
    "        d = calib_summary(calib)\n",
    "        print(f\"\\n[{name}] size=({d.get('width')}x{d.get('height')}), fx_fy_cx_cy={d.get('fx_fy_cx_cy')}\")\n",
    "        if \"extrinsic_4x4\" in d:\n",
    "            print(\"extrinsic_4x4:\\n\", d[\"extrinsic_4x4\"])\n",
    "\n",
    "calib_map = get_camera_calibration_map(frame)\n",
    "print(\"num camera_calibrations:\", len(calib_map))\n",
    "print_camera_calibrations(calib_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afae45d",
   "metadata": {},
   "source": [
    "### Block 6ï¼šé€šç”¨â€œåˆ—å‡ºå­ message çš„ set/defined å­—æ®µâ€å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad73ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_submessage(parent_msg, field_name, title=None, show_all_defined=True, max_set_fields=80):\n",
    "    \"\"\"\n",
    "    parent_msg: protobuf message\n",
    "    field_name: str, e.g., \"context\" / \"pose\"\n",
    "    \"\"\"\n",
    "    sub = getattr(parent_msg, field_name, None)\n",
    "    if sub is None:\n",
    "        print(f\"\\nâŒ {field_name} not found on this message.\")\n",
    "        return None\n",
    "\n",
    "    t = title or field_name\n",
    "    pb_set_fields(sub, t, max_fields=max_set_fields)\n",
    "    if show_all_defined:\n",
    "        pb_all_fields(sub, f\"{t}\")\n",
    "    return sub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81a6fea",
   "metadata": {},
   "source": [
    "### Block 7ï¼šframe.context æ·±æŒ–ï¼ˆframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc89bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== frame.context (set fields) ===\n",
      "- name: 5bef8f2e82697e56d4151d1462088b90-206\n",
      "- camera_calibrations: repeated len=8\n",
      "\n",
      "=== frame.context (all defined fields) ===\n",
      "- name: scalar, type=9\n",
      "- camera_calibrations: repeated, type=11\n",
      "- laser_calibrations: repeated, type=11\n",
      "- stats: scalar, type=11\n",
      "\n",
      "context defined fields: ['name', 'camera_calibrations', 'laser_calibrations', 'stats']\n",
      "\n",
      "num camera_calibrations: 8\n",
      "\n",
      "=== context.camera_calibrations[0] (set) (set fields) ===\n",
      "- name: 2\n",
      "- intrinsic: repeated len=9\n",
      "- extrinsic: message<Transform> subfields=1\n",
      "- width: 972\n",
      "- height: 1079\n",
      "- rolling_shutter_direction: 2\n",
      "\n",
      "=== context.camera_calibrations[0] (defined) (all defined fields) ===\n",
      "- name: scalar, type=14\n",
      "- intrinsic: repeated, type=1\n",
      "- extrinsic: scalar, type=11\n",
      "- width: scalar, type=5\n",
      "- height: scalar, type=5\n",
      "- rolling_shutter_direction: scalar, type=14\n"
     ]
    }
   ],
   "source": [
    "context = inspect_submessage(frame, \"context\", title=\"frame.context\", show_all_defined=True)\n",
    "\n",
    "# å¦‚æœä½ åªæƒ³çœ‹ context é‡Œæœ‰å“ªäº›å­—æ®µåï¼ˆå®šä¹‰å±‚é¢ï¼‰\n",
    "print(\"\\ncontext defined fields:\", [f.name for f in context.DESCRIPTOR.fields])\n",
    "\n",
    "# å¦‚æœ camera_calibrations åœ¨é‡Œé¢ï¼Œå°±æ‰“å°ä¸€ä¸‹æ¯ä¸ª calibration æ˜¯å¦æœ‰ intrinsic/extrinsic\n",
    "if hasattr(context, \"camera_calibrations\"):\n",
    "    print(\"\\nnum camera_calibrations:\", len(context.camera_calibrations))\n",
    "    # åªæ‰“å°ç¬¬ä¸€ä¸ª calibration çš„ set fields & all fieldsï¼Œç¡®è®¤ç»“æ„\n",
    "    if len(context.camera_calibrations) > 0:\n",
    "        calib0 = context.camera_calibrations[0]\n",
    "        pb_set_fields(calib0, \"context.camera_calibrations[0] (set)\", max_fields=80)\n",
    "        pb_all_fields(calib0, \"context.camera_calibrations[0] (defined)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c7028",
   "metadata": {},
   "source": [
    "### Block 8ï¼šframe.pose ä¸ frame.map_pose_offsetï¼ˆframe ä¸“ç”¨ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fa4d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== frame.pose (set fields) ===\n",
      "\n",
      "=== frame.pose (all defined fields) ===\n",
      "- transform: repeated, type=1\n",
      "\n",
      "=== frame.map_pose_offset (set fields) ===\n",
      "\n",
      "=== frame.map_pose_offset (all defined fields) ===\n",
      "- x: scalar, type=1\n",
      "- y: scalar, type=1\n",
      "- z: scalar, type=1\n"
     ]
    }
   ],
   "source": [
    "# 8.1 æ£€æŸ¥ poseï¼ˆæ˜¯å¦è¢« setï¼‰\n",
    "pose = inspect_submessage(frame, \"pose\", title=\"frame.pose\", show_all_defined=True)\n",
    "\n",
    "# 8.2 æ£€æŸ¥ map_pose_offsetï¼ˆä¸åœ°å›¾åæ ‡ç³»ç›¸å…³ï¼‰\n",
    "map_pose_offset = inspect_submessage(frame, \"map_pose_offset\", title=\"frame.map_pose_offset\", show_all_defined=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681080c",
   "metadata": {},
   "source": [
    "### Block 9ï¼šframe.labelsï¼ˆå…ˆåšâ€œå­˜åœ¨æ€§æ¢æµ‹â€ï¼Œframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f42343d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== frame.laser_labels === len=0\n",
      "\n",
      "=== frame.camera_labels === len=0\n",
      "\n",
      "=== frame.projected_lidar_labels === len=0\n"
     ]
    }
   ],
   "source": [
    "def inspect_repeated_field(parent_msg, field_name, max_show=3):\n",
    "    \"\"\"æ‰“å° repeated å­—æ®µé•¿åº¦ï¼Œå¹¶å¯¹å‰ max_show ä¸ªå…ƒç´ åš set-fields æ¦‚è§ˆ\"\"\"\n",
    "    if not hasattr(parent_msg, field_name):\n",
    "        print(f\"\\nâŒ {field_name} not found.\")\n",
    "        return None\n",
    "\n",
    "    val = getattr(parent_msg, field_name)\n",
    "    try:\n",
    "        n = len(val)\n",
    "    except TypeError:\n",
    "        print(f\"\\nâš ï¸ {field_name} exists but has no len() (unexpected).\")\n",
    "        return val\n",
    "\n",
    "    print(f\"\\n=== frame.{field_name} === len={n}\")\n",
    "    if n > 0:\n",
    "        for i in range(min(max_show, n)):\n",
    "            pb_set_fields(val[i], f\"{field_name}[{i}] (set)\", max_fields=60)\n",
    "            pb_all_fields(val[i], f\"{field_name}[{i}] (defined)\")\n",
    "    return val\n",
    "\n",
    "laser_labels = inspect_repeated_field(frame, \"laser_labels\", max_show=1)\n",
    "camera_labels = inspect_repeated_field(frame, \"camera_labels\", max_show=1)\n",
    "proj_lidar_labels = inspect_repeated_field(frame, \"projected_lidar_labels\", max_show=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f601b",
   "metadata": {},
   "source": [
    "### Block 10ï¼šframe.map_featuresï¼ˆå…ˆåšâ€œç»“æ„æ¢æµ‹â€ï¼Œframe ä¸“ç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2d9b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== frame.map_features === len=0\n"
     ]
    }
   ],
   "source": [
    "map_features = inspect_repeated_field(frame, \"map_features\", max_show=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1af14cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total defined fields: 11\n",
      "context\n",
      "timestamp_micros\n",
      "pose\n",
      "images\n",
      "lasers\n",
      "laser_labels\n",
      "projected_lidar_labels\n",
      "camera_labels\n",
      "no_label_zones\n",
      "map_features\n",
      "map_pose_offset\n"
     ]
    }
   ],
   "source": [
    "print(\"Total defined fields:\", len(frame.DESCRIPTOR.fields))\n",
    "for f in frame.DESCRIPTOR.fields:\n",
    "    print(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f7b22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a9da536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_e2ed(raw_bytes):\n",
    "    m = wod_e2ed_pb2.E2EDFrame()\n",
    "    m.ParseFromString(raw_bytes)\n",
    "    return m\n",
    "\n",
    "def get_context_name(frame):\n",
    "    # Waymo Frame å¸¸è§ï¼šframe.context.name\n",
    "    if hasattr(frame, \"context\") and hasattr(frame.context, \"name\") and frame.context.name:\n",
    "        return frame.context.name\n",
    "    return None\n",
    "\n",
    "def get_timestamp_micros(frame):\n",
    "    # ä½ è¿™æ¡æ ·æœ¬æ˜¾ç¤ºæ˜¯ 0ï¼Œä½†æˆ‘ä»¬è¿˜æ˜¯ç»Ÿä¸€å–ä¸€ä¸‹\n",
    "    if hasattr(frame, \"timestamp_micros\"):\n",
    "        return int(frame.timestamp_micros)\n",
    "    return None\n",
    "\n",
    "def scan_tfrecord_for_segments(filename, max_records=None):\n",
    "    ds = tf.data.TFRecordDataset(filename, compression_type=(\"GZIP\" if filename.endswith(\".gz\") else \"\"))\n",
    "    seg = defaultdict(lambda: {\"count\": 0, \"tmin\": None, \"tmax\": None, \"idx_first\": None, \"idx_last\": None})\n",
    "\n",
    "    for i, r in enumerate(ds):\n",
    "        if max_records is not None and i >= max_records:\n",
    "            break\n",
    "        e2e = parse_e2ed(r.numpy())\n",
    "        fr = e2e.frame\n",
    "\n",
    "        ctx = get_context_name(fr) or \"UNKNOWN_CONTEXT\"\n",
    "        t = get_timestamp_micros(fr)\n",
    "\n",
    "        s = seg[ctx]\n",
    "        s[\"count\"] += 1\n",
    "        if s[\"idx_first\"] is None:\n",
    "            s[\"idx_first\"] = i\n",
    "        s[\"idx_last\"] = i\n",
    "\n",
    "        if t is not None:\n",
    "            if s[\"tmin\"] is None or t < s[\"tmin\"]:\n",
    "                s[\"tmin\"] = t\n",
    "            if s[\"tmax\"] is None or t > s[\"tmax\"]:\n",
    "                s[\"tmax\"] = t\n",
    "\n",
    "    # æ‰“å°æ‘˜è¦ï¼šæ¯ä¸ª context æœ‰å¤šå°‘æ¡è®°å½•ã€æ—¶é—´è·¨åº¦\n",
    "    print(\"=== Segment summary in this TFRecord ===\")\n",
    "    for ctx, s in sorted(seg.items(), key=lambda kv: kv[1][\"count\"], reverse=True)[:10]:\n",
    "        if s[\"tmin\"] is not None and s[\"tmax\"] is not None and s[\"tmax\"] > s[\"tmin\"]:\n",
    "            dur = (s[\"tmax\"] - s[\"tmin\"]) / 1e6\n",
    "            print(f\"- {ctx}: n={s['count']}, durationâ‰ˆ{dur:.2f}s, idx=[{s['idx_first']},{s['idx_last']}]\")\n",
    "        else:\n",
    "            print(f\"- {ctx}: n={s['count']}, duration=UNKNOWN (timestamp missing/zero), idx=[{s['idx_first']},{s['idx_last']}]\")\n",
    "\n",
    "    return seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d04e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Segment summary in this TFRecord ===\n",
      "- 5bef8f2e82697e56d4151d1462088b90-206: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[0,0]\n",
      "- fc9aa7a016420317dae6d3fc3903f401-032: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[1,1]\n",
      "- 1f4f28e83c40d27675ed1eb4f4e4dacf-172: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[2,2]\n",
      "- df066120eff5488fb7d9b5304243db77-192: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[3,3]\n",
      "- b893f870bc2a934a69a172493177c48c-067: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[4,4]\n",
      "- 0931d95064ce771d7216263d53be126f-078: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[5,5]\n",
      "- 60a492fa895296ec6c1fac483bc400ca-210: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[6,6]\n",
      "- 62e779c32b94ff46ede44346d94a97f5-160: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[7,7]\n",
      "- adba328ccd36b14cb2d1f2c777859861-131: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[8,8]\n",
      "- 38561ca659f7ba32383f3f1cad122546-213: n=1, duration=UNKNOWN (timestamp missing/zero), idx=[9,9]\n"
     ]
    }
   ],
   "source": [
    "seg_info = scan_tfrecord_for_segments(FILENAME, max_records=2000)  # å…ˆæ‰«å‰2000æ¡è¯•è¯•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a20768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_context_name(ctx_name: str):\n",
    "    \"\"\"\n",
    "    æœŸæœ›æ ¼å¼ï¼š<hex>-<frame_idx>\n",
    "    è¿”å›ï¼š(segment_id, frame_idx[int or None])\n",
    "    \"\"\"\n",
    "    if ctx_name is None:\n",
    "        return None, None\n",
    "    if \"-\" not in ctx_name:\n",
    "        return ctx_name, None\n",
    "    base, suf = ctx_name.rsplit(\"-\", 1)\n",
    "    try:\n",
    "        return base, int(suf)\n",
    "    except ValueError:\n",
    "        return ctx_name, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36c1419c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "\n",
    "def parse_e2ed(raw_bytes):\n",
    "    m = wod_e2ed_pb2.E2EDFrame()\n",
    "    m.ParseFromString(raw_bytes)\n",
    "    return m\n",
    "\n",
    "def get_context_name(frame):\n",
    "    if hasattr(frame, \"context\") and hasattr(frame.context, \"name\") and frame.context.name:\n",
    "        return frame.context.name\n",
    "    return None\n",
    "\n",
    "def scan_tfrecord_segments_by_base(filename, max_records=None, fps_assumption=10):\n",
    "    ds = tf.data.TFRecordDataset(filename, compression_type=(\"GZIP\" if filename.endswith(\".gz\") else \"\"))\n",
    "\n",
    "    seg = defaultdict(lambda: {\"count\": 0, \"idx_min\": None, \"idx_max\": None})\n",
    "    for i, r in enumerate(ds):\n",
    "        if max_records is not None and i >= max_records:\n",
    "            break\n",
    "\n",
    "        e2e = parse_e2ed(r.numpy())\n",
    "        ctx = get_context_name(e2e.frame) or \"UNKNOWN\"\n",
    "        seg_id, frame_idx = split_context_name(ctx)\n",
    "\n",
    "        s = seg[seg_id]\n",
    "        s[\"count\"] += 1\n",
    "        if frame_idx is not None:\n",
    "            s[\"idx_min\"] = frame_idx if s[\"idx_min\"] is None else min(s[\"idx_min\"], frame_idx)\n",
    "            s[\"idx_max\"] = frame_idx if s[\"idx_max\"] is None else max(s[\"idx_max\"], frame_idx)\n",
    "\n",
    "    print(\"=== Segment summary (grouped by base segment id) ===\")\n",
    "    items = sorted(seg.items(), key=lambda kv: kv[1][\"count\"], reverse=True)[:10]\n",
    "    for seg_id, s in items:\n",
    "        if s[\"idx_min\"] is not None and s[\"idx_max\"] is not None and s[\"idx_max\"] >= s[\"idx_min\"]:\n",
    "            approx_dur = (s[\"idx_max\"] - s[\"idx_min\"] + 1) / fps_assumption\n",
    "            print(f\"- {seg_id}: n={s['count']} frames, frame_idx=[{s['idx_min']},{s['idx_max']}], durationâ‰ˆ{approx_dur:.2f}s @ {fps_assumption}Hz\")\n",
    "        else:\n",
    "            print(f\"- {seg_id}: n={s['count']} frames, frame_idx=UNKNOWN\")\n",
    "    return seg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7a6660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Segment summary (grouped by base segment id) ===\n",
      "- 62502fb60c74f34c9edf8ad3c7461776: n=8 frames, frame_idx=[46,228], durationâ‰ˆ18.30s @ 10Hz\n",
      "- 758d558fd6217582d6601940af85c5cb: n=8 frames, frame_idx=[39,197], durationâ‰ˆ15.90s @ 10Hz\n",
      "- ef06b076c2f0910d2499e33961803074: n=7 frames, frame_idx=[53,202], durationâ‰ˆ15.00s @ 10Hz\n",
      "- 1999b9e4fa6865bcc0a3d320cd4384ba: n=7 frames, frame_idx=[49,212], durationâ‰ˆ16.40s @ 10Hz\n",
      "- fb0ed944efebd34d756103188d59da85: n=7 frames, frame_idx=[20,223], durationâ‰ˆ20.40s @ 10Hz\n",
      "- d2f02321a3360119781084482e33cf9d: n=7 frames, frame_idx=[86,199], durationâ‰ˆ11.40s @ 10Hz\n",
      "- 4fe50a077365cafbfd8cc0778110391c: n=7 frames, frame_idx=[53,204], durationâ‰ˆ15.20s @ 10Hz\n",
      "- 27b862196b866184a3c6b28dd1cdfbba: n=6 frames, frame_idx=[17,201], durationâ‰ˆ18.50s @ 10Hz\n",
      "- f1dd0e328596edd3c4cd977a0d09aef5: n=6 frames, frame_idx=[63,207], durationâ‰ˆ14.50s @ 10Hz\n",
      "- fa7cf34b3f20b157a601f3d5b72cab7c: n=6 frames, frame_idx=[81,210], durationâ‰ˆ13.00s @ 10Hz\n"
     ]
    }
   ],
   "source": [
    "seg = scan_tfrecord_segments_by_base(FILENAME, max_records=5000, fps_assumption=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9086e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def cam_name_from_id(cam_id):\n",
    "    # ä½ ä¹‹å‰å·²ç»ç”¨ DESCRIPTOR æ–¹å¼æå®š enumï¼Œè¿™é‡Œç»™ä¸€ä¸ªç‹¬ç«‹ç‰ˆæœ¬\n",
    "    try:\n",
    "        return open_dataset.CameraName.DESCRIPTOR.values_by_number[int(cam_id)].name\n",
    "    except Exception:\n",
    "        return str(cam_id)\n",
    "\n",
    "def get_camera_image(frame, cam_name=\"FRONT\"):\n",
    "    # cam_name: \"FRONT\", \"FRONT_LEFT\", ...\n",
    "    cam_id = open_dataset.CameraName.Value(cam_name)\n",
    "    for img in frame.images:\n",
    "        if int(img.name) == int(cam_id):\n",
    "            return tf.io.decode_jpeg(img.image).numpy()  # RGB\n",
    "    return None\n",
    "\n",
    "def export_segment_video_from_file(filename, out_mp4, target_seg_id, cam_name=\"FRONT\", fps=10, max_frames=None):\n",
    "    ds = tf.data.TFRecordDataset(filename, compression_type=(\"GZIP\" if filename.endswith(\".gz\") else \"\"))\n",
    "\n",
    "    frames = []\n",
    "    for r in ds:\n",
    "        e2e = parse_e2ed(r.numpy())\n",
    "        ctx = get_context_name(e2e.frame)\n",
    "        seg_id, frame_idx = split_context_name(ctx or \"\")\n",
    "        if seg_id != target_seg_id:\n",
    "            continue\n",
    "\n",
    "        img = get_camera_image(e2e.frame, cam_name=cam_name)\n",
    "        if img is None:\n",
    "            continue\n",
    "        frames.append((frame_idx if frame_idx is not None else 0, img))\n",
    "\n",
    "        if max_frames is not None and len(frames) >= max_frames:\n",
    "            break\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"æ²¡åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œæ‰¾åˆ°è¯¥ segment_id çš„å¸§ï¼›å¯èƒ½è¯¥ segment åˆ†æ•£åœ¨å…¶ä»– shardã€‚\")\n",
    "\n",
    "    frames.sort(key=lambda x: x[0])  # æŒ‰ frame_idx æ’åº\n",
    "    h, w = frames[0][1].shape[:2]\n",
    "    vw = cv2.VideoWriter(out_mp4, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    for _, rgb in frames:\n",
    "        bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "        vw.write(bgr)\n",
    "\n",
    "    vw.release()\n",
    "    print(f\"âœ… Saved: {out_mp4} | frames={len(frames)} | durationâ‰ˆ{len(frames)/fps:.2f}s @ {fps}Hz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdc53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98c4b772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… collected 7 unique frames from this file\n",
      "frame_idx range: 20 ~ 223\n",
      "âœ… Saved: fb0ed944efebd34d756103188d59da85_1_filled.mp4\n",
      "   written=204 frames, durationâ‰ˆ20.40s @ 10Hz\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# WOD-E2E: Reconstruct a video (single TFRecord shard)\n",
    "# - Collect frames for a given segment_id from ONE TFRecord file\n",
    "# - Export a filled video by repeating last frame to fill missing frame_idx\n",
    "# =========================\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# ---------- Parse ----------\n",
    "def parse_e2ed(raw_bytes: bytes):\n",
    "    m = wod_e2ed_pb2.E2EDFrame()\n",
    "    m.ParseFromString(raw_bytes)\n",
    "    return m\n",
    "\n",
    "def get_context_name(frame):\n",
    "    if hasattr(frame, \"context\") and hasattr(frame.context, \"name\") and frame.context.name:\n",
    "        return frame.context.name\n",
    "    return \"\"\n",
    "\n",
    "def split_context_name(ctx_name: str):\n",
    "    \"\"\"\n",
    "    Expected: <segment_hex>-<frame_idx>\n",
    "    Returns: (segment_id, frame_idx[int or None])\n",
    "    \"\"\"\n",
    "    if not ctx_name or \"-\" not in ctx_name:\n",
    "        return ctx_name, None\n",
    "    base, suf = ctx_name.rsplit(\"-\", 1)\n",
    "    try:\n",
    "        return base, int(suf)\n",
    "    except ValueError:\n",
    "        return ctx_name, None\n",
    "\n",
    "# ---------- Camera enum mapping (robust) ----------\n",
    "def cam_id_from_name(cam_name: str):\n",
    "    \"\"\"\n",
    "    Robust mapping from camera name (e.g., \"FRONT\") -> enum number,\n",
    "    without relying on .Value() / .Name() / values_by_name (which can vary by build).\n",
    "    \"\"\"\n",
    "    name = cam_name.split(\".\")[-1]  # tolerate \"CameraName.FRONT\"\n",
    "\n",
    "    # 1) Try protobuf enum wrapper API if exists\n",
    "    if hasattr(open_dataset.CameraName, \"Value\"):\n",
    "        try:\n",
    "            return int(open_dataset.CameraName.Value(name))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 2) Try DESCRIPTOR (may be EnumDescriptor, or other)\n",
    "    desc = getattr(open_dataset.CameraName, \"DESCRIPTOR\", None)\n",
    "    if desc is not None:\n",
    "        # EnumDescriptor usually has .values (list of EnumValueDescriptor)\n",
    "        values = getattr(desc, \"values\", None)\n",
    "        if values is not None:\n",
    "            for v in values:\n",
    "                if getattr(v, \"name\", None) == name:\n",
    "                    return int(getattr(v, \"number\"))\n",
    "        # Some builds expose values_by_number\n",
    "        vbn = getattr(desc, \"values_by_number\", None)\n",
    "        if isinstance(vbn, dict):\n",
    "            for num, v in vbn.items():\n",
    "                if getattr(v, \"name\", None) == name:\n",
    "                    return int(num)\n",
    "\n",
    "    # 3) If user passed a number-like string, accept it\n",
    "    try:\n",
    "        return int(cam_name)\n",
    "    except Exception:\n",
    "        # Print a small hint list if we can\n",
    "        hint = \"\"\n",
    "        if desc is not None and getattr(desc, \"values\", None) is not None:\n",
    "            hint = f\"\\nAvailable names example: {[v.name for v in desc.values[:10]]} ...\"\n",
    "        raise KeyError(f\"Unknown camera name: {cam_name}.{hint}\")\n",
    "\n",
    "def get_camera_image_rgb(frame, cam_name=\"FRONT\"):\n",
    "    \"\"\"\n",
    "    Return RGB image np.ndarray(H,W,3) or None\n",
    "    \"\"\"\n",
    "    cam_id = cam_id_from_name(cam_name)\n",
    "    for img in frame.images:\n",
    "        if int(img.name) == int(cam_id):\n",
    "            return tf.io.decode_jpeg(img.image).numpy()  # RGB\n",
    "    return None\n",
    "\n",
    "# ---------- Collect frames from ONE file ----------\n",
    "def collect_segment_frames_from_file(filename, target_seg_id, cam_name=\"FRONT\", max_records=None):\n",
    "    ds = tf.data.TFRecordDataset(\n",
    "        filename,\n",
    "        compression_type=(\"GZIP\" if filename.endswith(\".gz\") else \"\")\n",
    "    )\n",
    "\n",
    "    frames = []\n",
    "    for i, r in enumerate(ds):\n",
    "        if max_records is not None and i >= max_records:\n",
    "            break\n",
    "\n",
    "        e2e = parse_e2ed(r.numpy())\n",
    "        fr = e2e.frame\n",
    "        ctx = get_context_name(fr)\n",
    "\n",
    "        seg_id, frame_idx = split_context_name(ctx)\n",
    "        if seg_id != target_seg_id:\n",
    "            continue\n",
    "\n",
    "        rgb = get_camera_image_rgb(fr, cam_name=cam_name)\n",
    "        if rgb is None:\n",
    "            continue\n",
    "\n",
    "        frames.append((frame_idx if frame_idx is not None else -1, rgb))\n",
    "\n",
    "    # sort + dedup by frame_idx\n",
    "    frames.sort(key=lambda x: x[0])\n",
    "    dedup = {}\n",
    "    for idx, rgb in frames:\n",
    "        if idx not in dedup:\n",
    "            dedup[idx] = rgb\n",
    "    frames = sorted(dedup.items(), key=lambda x: x[0])\n",
    "\n",
    "    print(f\"âœ… collected {len(frames)} unique frames from this file\")\n",
    "    if frames:\n",
    "        print(\"frame_idx range:\", frames[0][0], \"~\", frames[-1][0])\n",
    "    return frames\n",
    "\n",
    "# ---------- Export video (fill gaps by repeating last frame) ----------\n",
    "def export_video_fill_gaps(frames, out_mp4, fps=10):\n",
    "    \"\"\"\n",
    "    frames: list[(frame_idx, rgb)]\n",
    "    Fill missing indices by repeating last available frame.\n",
    "    Durationâ‰ˆ(idx_max-idx_min+1)/fps\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"frames is empty\")\n",
    "\n",
    "    idxs = [i for i, _ in frames]\n",
    "    if any(i < 0 for i in idxs):\n",
    "        raise RuntimeError(\"frame_idx missing (-1). Cannot fill by idx; check context.name format.\")\n",
    "\n",
    "    idx_min, idx_max = idxs[0], idxs[-1]\n",
    "    table = {i: rgb for i, rgb in frames}\n",
    "\n",
    "    h, w = frames[0][1].shape[:2]\n",
    "    vw = cv2.VideoWriter(out_mp4, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    last = table[idx_min]\n",
    "    written = 0\n",
    "    for i in range(idx_min, idx_max + 1):\n",
    "        if i in table:\n",
    "            last = table[i]\n",
    "        vw.write(cv2.cvtColor(last, cv2.COLOR_RGB2BGR))\n",
    "        written += 1\n",
    "\n",
    "    vw.release()\n",
    "    print(f\"âœ… Saved: {out_mp4}\")\n",
    "    print(f\"   written={written} frames, durationâ‰ˆ{written/fps:.2f}s @ {fps}Hz\")\n",
    "\n",
    "# =========================\n",
    "# RUN (edit these 3 lines)\n",
    "# =========================\n",
    "SEG_ID = \"fb0ed944efebd34d756103188d59da85\"  # your ~20.40s example\n",
    "CAM = \"1\"                                 # try: \"FRONT_LEFT\" / \"FRONT_RIGHT\"\n",
    "FPS = 10\n",
    "\n",
    "frames = collect_segment_frames_from_file(FILENAME, SEG_ID, cam_name=CAM)\n",
    "export_video_fill_gaps(frames, f\"{SEG_ID}_{CAM}_filled.mp4\", fps=FPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cc7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665bf288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b00dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b95c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca884df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af6dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c20a781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def parse_e2ed(raw_bytes: bytes):\n",
    "    m = wod_e2ed_pb2.E2EDFrame()\n",
    "    m.ParseFromString(raw_bytes)\n",
    "    return m\n",
    "\n",
    "def split_context_name(ctx_name: str):\n",
    "    \"\"\"'<segment>-<idx>' -> (segment_id, idx:int or None)\"\"\"\n",
    "    if not ctx_name or \"-\" not in ctx_name:\n",
    "        return ctx_name, None\n",
    "    base, suf = ctx_name.rsplit(\"-\", 1)\n",
    "    try:\n",
    "        return base, int(suf)\n",
    "    except ValueError:\n",
    "        return ctx_name, None\n",
    "\n",
    "def get_keyframe_index(e2e):\n",
    "    ctx = e2e.frame.context.name if hasattr(e2e.frame, \"context\") else \"\"\n",
    "    seg_id, idx = split_context_name(ctx)\n",
    "    return seg_id, idx, ctx\n",
    "\n",
    "def _extract_repeated_scalar_states(states_obj, keys=(\"pos_x\",\"pos_y\",\"pos_z\",\"vel_x\",\"vel_y\",\"accel_x\",\"accel_y\")):\n",
    "    \"\"\"\n",
    "    é’ˆå¯¹ä½ ç›®å‰è§‚å¯Ÿåˆ°çš„ EgoTrajectoryStatesï¼šå¾ˆå¤šå­—æ®µæ˜¯ repeated scalarï¼ˆpos_x ç­‰ï¼‰\n",
    "    è¿”å› dict[k]=np.array, ä»¥åŠé•¿åº¦ Lï¼ˆä»¥ pos_x ä¸ºå‡†ï¼‰\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for k in keys:\n",
    "        if hasattr(states_obj, k):\n",
    "            v = getattr(states_obj, k)\n",
    "            # v æ˜¯ RepeatedScalarContainer\n",
    "            out[k] = np.array(list(v), dtype=np.float32)\n",
    "    L = len(out[\"pos_x\"]) if \"pos_x\" in out else (len(next(iter(out.values()))) if out else 0)\n",
    "    return out, L\n",
    "\n",
    "def extract_record_features(e2e):\n",
    "    \"\"\"\n",
    "    æŠŠä¸€æ¡ record çš„å…³é”®å­—æ®µæŠ½å‡ºæ¥ï¼ˆä¸åšâ€œå¯¹é½â€ï¼Œåªä¿ç•™ç›¸å¯¹çª—å£ï¼‰\n",
    "    \"\"\"\n",
    "    seg_id, key_idx, key_id = get_keyframe_index(e2e)\n",
    "\n",
    "    # intent (int)\n",
    "    intent = int(getattr(e2e, \"intent\", -1))\n",
    "\n",
    "    # past/future (relative window)\n",
    "    past_dict, past_L = _extract_repeated_scalar_states(getattr(e2e, \"past_states\", None))\n",
    "    fut_dict,  fut_L  = _extract_repeated_scalar_states(getattr(e2e, \"future_states\", None))\n",
    "\n",
    "    # preference trajectories: å…ˆåšâ€œé€šç”¨æ‘˜è¦æå–â€\n",
    "    prefs = []\n",
    "    if hasattr(e2e, \"preference_trajectories\"):\n",
    "        for p in e2e.preference_trajectories:\n",
    "            d = {}\n",
    "            if hasattr(p, \"preference_score\"):\n",
    "                d[\"preference_score\"] = float(p.preference_score)\n",
    "            # å¦‚æœè¿˜æœ‰åˆ«çš„å­—æ®µï¼ˆæ¯”å¦‚è½¨è¿¹ç‚¹ï¼‰ï¼Œä½ åé¢å¯ä»¥ç»§ç»­åŠ \n",
    "            prefs.append(d)\n",
    "\n",
    "    return {\n",
    "        \"seg_id\": seg_id,\n",
    "        \"key_idx\": key_idx,\n",
    "        \"key_id\": key_id,\n",
    "        \"intent\": intent,\n",
    "        \"past\": past_dict, \"past_L\": past_L,\n",
    "        \"future\": fut_dict, \"future_L\": fut_L,\n",
    "        \"prefs\": prefs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60aacdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tfrecords(folder):\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.tfrecord*\")))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No tfrecord under: {folder}\")\n",
    "    return files\n",
    "\n",
    "def collect_segment_records(val_folder, target_seg_id, max_files=None):\n",
    "    \"\"\"\n",
    "    æ‰«æ val_folder ä¸‹æ‰€æœ‰ tfrecord shardï¼ŒæŠŠå±äº target_seg_id çš„ record æ”¶é›†èµ·æ¥\n",
    "    è¿”å› records: list[dict]ï¼ˆå·²æå– featuresï¼‰\n",
    "    \"\"\"\n",
    "    files = list_tfrecords(val_folder)\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    records = []\n",
    "    for fp in files:\n",
    "        ds = tf.data.TFRecordDataset(fp, compression_type=(\"GZIP\" if fp.endswith(\".gz\") else \"\"))\n",
    "        for r in ds:\n",
    "            e2e = parse_e2ed(r.numpy())\n",
    "            seg_id, key_idx, _ = get_keyframe_index(e2e)\n",
    "            if seg_id != target_seg_id:\n",
    "                continue\n",
    "            records.append(extract_record_features(e2e))\n",
    "\n",
    "    # æŒ‰ key_idx æ’åº\n",
    "    records = [x for x in records if x[\"key_idx\"] is not None]\n",
    "    records.sort(key=lambda x: x[\"key_idx\"])\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c7dd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_segment(records, fps=10):\n",
    "    if not records:\n",
    "        print(\"No records for this segment.\")\n",
    "        return\n",
    "\n",
    "    idxs = np.array([r[\"key_idx\"] for r in records], dtype=int)\n",
    "    idx_min, idx_max = int(idxs.min()), int(idxs.max())\n",
    "    approx_duration = (idx_max - idx_min + 1) / float(fps)\n",
    "\n",
    "    past_Ls = [r[\"past_L\"] for r in records]\n",
    "    fut_Ls  = [r[\"future_L\"] for r in records]\n",
    "    intents = [r[\"intent\"] for r in records]\n",
    "\n",
    "    print(\"=== Segment summary ===\")\n",
    "    print(\"segment_id:\", records[0][\"seg_id\"])\n",
    "    print(f\"keyframes: {len(records)} | key_idx range: [{idx_min}, {idx_max}] | durationâ‰ˆ{approx_duration:.2f}s @ {fps}Hz\")\n",
    "    print(\"past_L (min/median/max):\", int(np.min(past_Ls)), int(np.median(past_Ls)), int(np.max(past_Ls)))\n",
    "    print(\"future_L (min/median/max):\", int(np.min(fut_Ls)), int(np.median(fut_Ls)), int(np.max(fut_Ls)))\n",
    "\n",
    "    # intent timelineï¼ˆç²—çœ‹æ˜¯å¦åŸºæœ¬æ’å®šï¼‰\n",
    "    uniq, cnt = np.unique(intents, return_counts=True)\n",
    "    print(\"intent counts:\", dict(zip([int(u) for u in uniq], [int(c) for c in cnt])))\n",
    "    # å¦‚æœæƒ³çœ‹å˜åŒ–ç‚¹ï¼š\n",
    "    changes = []\n",
    "    for i in range(1, len(records)):\n",
    "        if records[i][\"intent\"] != records[i-1][\"intent\"]:\n",
    "            changes.append((records[i-1][\"key_idx\"], records[i][\"key_idx\"], records[i-1][\"intent\"], records[i][\"intent\"]))\n",
    "    print(\"intent changes (prev_idx->next_idx, prev_intent->next_intent):\", changes[:10])\n",
    "\n",
    "    # preference_scores æ±‡æ€»\n",
    "    scores = []\n",
    "    for r in records:\n",
    "        for p in r[\"prefs\"]:\n",
    "            if \"preference_score\" in p:\n",
    "                scores.append(p[\"preference_score\"])\n",
    "    if scores:\n",
    "        scores = np.array(scores, dtype=float)\n",
    "        print(\"preference_score stats:\", {\"min\": float(scores.min()), \"mean\": float(scores.mean()), \"max\": float(scores.max()), \"n\": int(scores.size)})\n",
    "    else:\n",
    "        print(\"preference_score: none found in these records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7cd0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ego_xy_timeline(records, fps=10):\n",
    "    \"\"\"\n",
    "    è¿”å› dict:\n",
    "      timeline[\"idx\"] = sorted absolute indices\n",
    "      timeline[\"x\"], timeline[\"y\"] = merged positions (NaN if missing)\n",
    "    åˆå¹¶ç­–ç•¥ï¼šåŒä¸€ä¸ª abs_idx å¦‚æœå‡ºç°å¤šæ¬¡ï¼Œå–å¹³å‡\n",
    "    \"\"\"\n",
    "    if not records:\n",
    "        return None\n",
    "\n",
    "    # æ”¶é›† abs_idx -> list[x], list[y]\n",
    "    agg = {}\n",
    "    for r in records:\n",
    "        key = r[\"key_idx\"]\n",
    "        past = r[\"past\"]\n",
    "        fut  = r[\"future\"]\n",
    "\n",
    "        # çº¦å®šï¼špast çš„æœ€åä¸€ä¸ªç‚¹æœ€æ¥è¿‘ key_idxï¼ˆä½ å¯ä»¥æŒ‰éœ€è¦è°ƒæ•´ï¼‰\n",
    "        # è¿™é‡Œç”¨ offsets = [-past_L, ..., -1]\n",
    "        if \"pos_x\" in past and \"pos_y\" in past:\n",
    "            L = len(past[\"pos_x\"])\n",
    "            offsets = np.arange(-L, 0, dtype=int)\n",
    "            for off, x, y in zip(offsets, past[\"pos_x\"], past[\"pos_y\"]):\n",
    "                abs_i = key + int(off)\n",
    "                agg.setdefault(abs_i, {\"x\": [], \"y\": []})\n",
    "                agg[abs_i][\"x\"].append(float(x))\n",
    "                agg[abs_i][\"y\"].append(float(y))\n",
    "\n",
    "        # future: offsets = [1,2,...,L]\n",
    "        if \"pos_x\" in fut and \"pos_y\" in fut:\n",
    "            L = len(fut[\"pos_x\"])\n",
    "            offsets = np.arange(1, L+1, dtype=int)\n",
    "            for off, x, y in zip(offsets, fut[\"pos_x\"], fut[\"pos_y\"]):\n",
    "                abs_i = key + int(off)\n",
    "                agg.setdefault(abs_i, {\"x\": [], \"y\": []})\n",
    "                agg[abs_i][\"x\"].append(float(x))\n",
    "                agg[abs_i][\"y\"].append(float(y))\n",
    "\n",
    "    idxs = sorted(agg.keys())\n",
    "    x = np.array([np.mean(agg[i][\"x\"]) if agg[i][\"x\"] else np.nan for i in idxs], dtype=np.float32)\n",
    "    y = np.array([np.mean(agg[i][\"y\"]) if agg[i][\"y\"] else np.nan for i in idxs], dtype=np.float32)\n",
    "\n",
    "    return {\"idx\": np.array(idxs, dtype=int), \"x\": x, \"y\": y, \"fps\": fps}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "612f348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ego_xy(tl):\n",
    "    idx = tl[\"idx\"]\n",
    "    x, y = tl[\"x\"], tl[\"y\"]\n",
    "    ok = np.isfinite(x) & np.isfinite(y)\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.plot(x[ok], y[ok])\n",
    "    plt.title(f\"Ego XY (points={ok.sum()}, idx[{idx.min()}..{idx.max()}])\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82a4b79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Segment summary ===\n",
      "segment_id: fb0ed944efebd34d756103188d59da85\n",
      "keyframes: 229 | key_idx range: [8, 236] | durationâ‰ˆ22.90s @ 10Hz\n",
      "past_L (min/median/max): 16 16 16\n",
      "future_L (min/median/max): 20 20 20\n",
      "intent counts: {1: 229}\n",
      "intent changes (prev_idx->next_idx, prev_intent->next_intent): []\n",
      "preference_score stats: {'min': -1.0, 'mean': -0.9592430858806404, 'max': 10.0, 'n': 687}\n"
     ]
    }
   ],
   "source": [
    "VAL_DIR = r\"/mnt/d/Datasets/WOD_E2E_Camera_v1/val\"  # ä½ è‡ªå·±ç¯å¢ƒçš„è·¯å¾„\n",
    "SEG_ID  = \"fb0ed944efebd34d756103188d59da85\"\n",
    "\n",
    "records = collect_segment_records(VAL_DIR, SEG_ID)\n",
    "summarize_segment(records, fps=10)\n",
    "\n",
    "tl = build_ego_xy_timeline(records, fps=10)\n",
    "if tl:\n",
    "    plot_ego_xy(tl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e98849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waymo_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
